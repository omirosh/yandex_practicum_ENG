{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#TF-IDF-и-логистическая-регрессия\" data-toc-modified-id=\"TF-IDF-и-логистическая-регрессия-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>TF-IDF и логистическая регрессия</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ тональности текста\n",
    "\n",
    "Нужно построить модель машинного обучения для определения токсичных комментариев.\n",
    "\n",
    "Метрика качества *F1* должна быть >= 0.75. \n",
    "\n",
    "Были использованы следующие модели:\n",
    "- CatBoost\n",
    "- TF-IDF + Logistic Regression\n",
    "\n",
    "**Описание данных**   \n",
    "Набор текстов с разметкой о токсичности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#импортирование нужных библиотек:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords') \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import spacy\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "\n",
    "#игнорирование предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  toxic\n",
      "0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1  D'aww! He matches this background colour I'm s...      0\n",
      "2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4  You, sir, are my hero. Any chance you remember...      0\n",
      "--------------\n",
      "(159571, 2)\n",
      "--------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print('--------------')\n",
    "print(data.shape)\n",
    "print('--------------')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, есть ли дисбаланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disbalance = data['toxic'].value_counts(normalize=True)\n",
    "disbalance.plot(kind='barh')\n",
    "disbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется значительный дисбаланс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем лемматизацию текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = data['text'].values\n",
    "display(corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemm_text = \" \".join([token.lemma_ for token in doc])\n",
    "        \n",
    "    return lemm_text\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    # удалим все кроме букв:\n",
    "    temp = re.sub(r\"[^a-zA-Z ]\", ' ', text)\n",
    "    \n",
    "    # удалим единичные символы:\n",
    "    temp = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', temp)\n",
    "    temp = re.sub(r'\\^[a-zA-Z]\\s+', ' ', temp) \n",
    "    \n",
    "    # множественные пробелы заменим на одинарный:\n",
    "    temp = re.sub(r'\\s+', ' ', temp, flags=re.I)\n",
    "        \n",
    "    # приведем к нижнему регистру:\n",
    "    temp = temp.lower()\n",
    "    \n",
    "    return \" \".join(temp.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e638def934314d2b8d69e82bb32aec38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='corpus size', max=159571.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1h 4min 7s, sys: 28.6 s, total: 1h 4min 36s\n",
      "Wall time: 1h 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in tqdm(range(0,corpus.shape[0]), desc='corpus size'):\n",
    "    data.loc[i, 'lemm_text'] = lemmatize(clear_text(corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим пропуски:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в связи с частой смертью ядра, лемматизированные тексты были сохранены в .csv файл\n",
    "#data.to_csv('texts_lemm.csv')\n",
    "data = pd.read_csv('texts_lemm.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "toxic        0\n",
       "lemm_text    7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under -PRON- use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>d aww -PRON- match this background colour m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hey man m really not try to edit war -PRON- ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>more can make any real suggestion on improveme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-PRON- sir be -PRON- hero any chance -PRON- re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           lemm_text\n",
       "0  explanation why the edit make under -PRON- use...\n",
       "1  d aww -PRON- match this background colour m se...\n",
       "2  hey man m really not try to edit war -PRON- ju...\n",
       "3  more can make any real suggestion on improveme...\n",
       "4  -PRON- sir be -PRON- hero any chance -PRON- re..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = data.drop(['text', 'toxic'], axis=1)\n",
    "labels = data['toxic']\n",
    "display(corpus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([], columns = ['model', 'f1', 'best_parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656, 1)\n",
      "(95742, 1)\n",
      "(31914, 1)\n",
      "(31915, 1)\n",
      "(159571, 1)\n"
     ]
    }
   ],
   "source": [
    "features_all, features_test, target_all, target_test = train_test_split(corpus, labels.values, test_size=0.2, random_state=12345, stratify=labels)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_all, target_all, test_size=0.25, random_state=12345, stratify=target_all)\n",
    "\n",
    "print(features_all.shape)\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['lemm_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6930628\ttest: 0.7292138\tbest: 0.7292138 (0)\ttotal: 923ms\tremaining: 15m 22s\n",
      "100:\tlearn: 0.7534018\ttest: 0.7647259\tbest: 0.7648561 (99)\ttotal: 1m 36s\tremaining: 14m 14s\n",
      "200:\tlearn: 0.7714466\ttest: 0.7689690\tbest: 0.7695704 (187)\ttotal: 3m 8s\tremaining: 12m 29s\n",
      "300:\tlearn: 0.7858450\ttest: 0.7704360\tbest: 0.7718761 (277)\ttotal: 4m 41s\tremaining: 10m 52s\n",
      "400:\tlearn: 0.7962826\ttest: 0.7696237\tbest: 0.7719239 (364)\ttotal: 6m 13s\tremaining: 9m 18s\n",
      "500:\tlearn: 0.8046657\ttest: 0.7705392\tbest: 0.7719239 (364)\ttotal: 7m 45s\tremaining: 7m 43s\n",
      "600:\tlearn: 0.8122941\ttest: 0.7700136\tbest: 0.7719239 (364)\ttotal: 9m 18s\tremaining: 6m 10s\n",
      "700:\tlearn: 0.8177390\ttest: 0.7692829\tbest: 0.7719239 (364)\ttotal: 10m 49s\tremaining: 4m 37s\n",
      "800:\tlearn: 0.8245475\ttest: 0.7697513\tbest: 0.7719239 (364)\ttotal: 12m 22s\tremaining: 3m 4s\n",
      "900:\tlearn: 0.8297968\ttest: 0.7703503\tbest: 0.7719239 (364)\ttotal: 13m 55s\tremaining: 1m 31s\n",
      "999:\tlearn: 0.8345827\ttest: 0.7699340\tbest: 0.7719239 (364)\ttotal: 15m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7719238613\n",
      "bestIteration = 364\n",
      "\n",
      "Shrink model to first 365 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f0c2047ced0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pool = Pool(\n",
    "    features_train, \n",
    "    target_train, \n",
    "    text_features=text_features, \n",
    "    feature_names=list(features_train)\n",
    ")\n",
    "valid_pool = Pool(\n",
    "    features_valid, \n",
    "    target_valid,\n",
    "    text_features=text_features, \n",
    "    feature_names=list(features_train)\n",
    ")\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'F1',\n",
    "    'use_best_model': True,\n",
    "    'verbose': 100,\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(**catboost_params)\n",
    "model.fit(train_pool, eval_set=valid_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append({'model': model, 'f1' : model.get_best_score()['validation']['F1'], 'best_parameters' : catboost_params}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785629150349055\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features_test)\n",
    "print(f1_score(target_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения f1 как на валидационной, так и на тестовой выборках удовлетворяет нашим требованиям (>=0.75). Обучим CatBoost со сбаланисированными весами, так как у нас дисбаланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8438473\ttest: 0.8674256\tbest: 0.8674256 (0)\ttotal: 903ms\tremaining: 15m 1s\n",
      "100:\tlearn: 0.8902611\ttest: 0.8993431\tbest: 0.8999298 (99)\ttotal: 1m 38s\tremaining: 14m 36s\n",
      "200:\tlearn: 0.9046933\ttest: 0.9034335\tbest: 0.9045284 (191)\ttotal: 3m 15s\tremaining: 12m 58s\n",
      "300:\tlearn: 0.9140141\ttest: 0.9036314\tbest: 0.9045284 (191)\ttotal: 4m 52s\tremaining: 11m 18s\n",
      "400:\tlearn: 0.9208660\ttest: 0.9042073\tbest: 0.9045284 (191)\ttotal: 6m 26s\tremaining: 9m 37s\n",
      "500:\tlearn: 0.9278149\ttest: 0.9047674\tbest: 0.9048767 (416)\ttotal: 8m 2s\tremaining: 8m\n",
      "600:\tlearn: 0.9331053\ttest: 0.9052895\tbest: 0.9052895 (600)\ttotal: 9m 37s\tremaining: 6m 23s\n",
      "700:\tlearn: 0.9375483\ttest: 0.9047147\tbest: 0.9054344 (657)\ttotal: 11m 12s\tremaining: 4m 46s\n",
      "800:\tlearn: 0.9423782\ttest: 0.9043549\tbest: 0.9054344 (657)\ttotal: 12m 47s\tremaining: 3m 10s\n",
      "900:\tlearn: 0.9468776\ttest: 0.9037875\tbest: 0.9054344 (657)\ttotal: 14m 23s\tremaining: 1m 34s\n",
      "999:\tlearn: 0.9507156\ttest: 0.9033554\tbest: 0.9054344 (657)\ttotal: 15m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9054344459\n",
      "bestIteration = 657\n",
      "\n",
      "Shrink model to first 658 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f0c2047d0d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'F1',\n",
    "    'use_best_model': True,\n",
    "    'verbose': 100,\n",
    "    'auto_class_weights':'Balanced'\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(**catboost_params)\n",
    "model.fit(train_pool, eval_set=valid_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>best_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.771924</td>\n",
       "      <td>{'iterations': 1000, 'learning_rate': 0.1, 'ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.905434</td>\n",
       "      <td>{'iterations': 1000, 'learning_rate': 0.1, 'ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model        f1  \\\n",
       "0  <catboost.core.CatBoostClassifier object at 0x...  0.771924   \n",
       "1  <catboost.core.CatBoostClassifier object at 0x...  0.905434   \n",
       "\n",
       "                                     best_parameters  \n",
       "0  {'iterations': 1000, 'learning_rate': 0.1, 'ev...  \n",
       "1  {'iterations': 1000, 'learning_rate': 0.1, 'ev...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.append({'model': model, 'f1' : model.get_best_score()['validation']['F1'], 'best_parameters' : catboost_params}, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7306517311608961\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(target_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1 для взвешенной модели на валидационной выборке очень быстро сошлась к высокому значению, видимо модель быстро переобучилась. На тестовой выборке результат не такой хороший."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features_train, features_valid, features_test, target_train, target_valid, target_test, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF и логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ядро постоянно умирает, тетрадка запускается только в 2 захода: сначала CatBoost, потом Лог регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(corpus, labels.values, test_size=0.25, random_state=12345, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119673, 1)\n",
      "(39891, 1)\n",
      "(159564, 1)\n",
      "Counter({0: 107504, 1: 12169})\n",
      "Counter({0: 35835, 1: 4056})\n",
      "Counter({0: 143339, 1: 16225})\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(corpus.shape)\n",
    "\n",
    "print(Counter(target_train))\n",
    "print(Counter(target_test))\n",
    "print(Counter(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (119673, 1500)\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words, max_features=1500, min_df=5, max_df=0.7) \n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train.lemm_text).toarray()\n",
    "\n",
    "print(\"Размер матрицы:\", tf_idf_train.shape)\n",
    "del features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6441297664650231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 9s, sys: 2min 3s, total: 14min 12s\n",
      "Wall time: 14min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params_logicRegression = {'solver': ['lbfgs', 'liblinear'],\n",
    "                      'C': np.logspace(-1,1, num=6)\n",
    "                      }\n",
    "grid = GridSearchCV(\n",
    "        estimator=LogisticRegression(random_state=12345, penalty='l2', class_weight='balanced'),\n",
    "        param_grid=params_logicRegression,\n",
    "        scoring='f1',\n",
    "        cv=3)\n",
    "\n",
    "grid.fit(tf_idf_train, target_train)\n",
    "\n",
    "display(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1</th>\n",
       "      <th>best_parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GridSearchCV(cv=3, error_score='raise-deprecat...</td>\n",
       "      <td>0.64413</td>\n",
       "      <td>{'C': 0.251188643150958, 'solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model       f1  \\\n",
       "0  GridSearchCV(cv=3, error_score='raise-deprecat...  0.64413   \n",
       "\n",
       "                               best_parameters  \n",
       "0  {'C': 0.251188643150958, 'solver': 'lbfgs'}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.append({'model' : grid, 'f1':grid.best_score_, 'best_parameters':grid.best_params_}, ignore_index=True)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(features_test.lemm_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6398176291793314\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(tf_idf_test)\n",
    "print(f1_score(target_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия, обученная на TF-IDF, показывает низкие значения f1 на кросс-валидации и на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Облегченный вариант регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.7389549702633815\n"
     ]
    }
   ],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords.words('english'), lowercase=True, min_df=0.0001) \n",
    "tf_idf_tr = count_tf_idf.fit_transform(features_train.lemm_text) \n",
    "\n",
    "tf_idf_te = count_tf_idf.transform(features_test.lemm_text) \n",
    "features_train = tf_idf_tr \n",
    "features_test = tf_idf_te\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', C=10.0, penalty='l2') \n",
    "model.fit(features_train, target_train) \n",
    "predictions = model.predict(features_test) \n",
    "f1_tfidf_te = f1_score(target_test, predictions) \n",
    "print('f1 на тестовой выборке:', f1_tfidf_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текстовые данные для оценки тональности были подготовлены и лемматизированы. Для обучения были выбраны модели CatBoostClassifier и Логистическая регрессия. Для обучения Логистической регрессии тексты были переведены в числовые представления с помощью TF-IDF. \n",
    "\n",
    "Наилучшее значение метрики f1 (>=0.75) показала модель CatBoostClassifier без параметра сбалансированных классов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
